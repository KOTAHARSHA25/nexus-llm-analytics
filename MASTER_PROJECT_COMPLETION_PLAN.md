# MASTER PROJECT COMPLETION PLAN
**Project:** Nexus LLM Analytics v2  
**Goal:** Restore functionality, fix critical bugs, and complete the "Full-Fledged" system.  
**Constraint:** Do not modify files directly; provide instructions.

---

## üèóÔ∏è 1. Executive Summary

To make the project 100% functional and "publication-ready", we must synchronize the Backend (Python) and Middleware (API Config), which are currently out of sync.

### Current Status
- **Backend:** Functional but fragile (API architecture drift).
- **Frontend:** Expects specific routes (`/analyze`, `/upload-documents`).
- **Tests:** Failing because they expect different routes (`/api/analyze`).

### The Strategy
We will **standardize everything** to a clean `/api/v1` structure. This ensures the project looks professional for your final presentation and passes all stability tests.

---

## üöÄ Phase 1: Backend Stabilization (The "Heartbeat" Fixes)

**Problem:** The backend crashes because the new modular code isn't fully connected to the old interfaces.

### Step 1.1: Fix `AgentFactory` Compatibility
**File to Edit:** `src/backend/agents/agent_factory.py`
**Action:** Add this method to the `AgentFactory` class to support legacy calls.

```python
    def create_agent(self, agent_type: str, **kwargs):
        """
        Legacy wrapper to fix 'AttributeError: AgentFactory has no attribute create_agent'
        """
        agent_map = {
            'data_analyst': self.data_analyst,
            'statistical': self.data_analyst,  # Alias
            'rag_specialist': self.rag_specialist,
            'rag': self.rag_specialist,        # Alias
            'reviewer': self.reviewer,
            'visualizer': self.visualizer,
            'reporter': self.reporter
        }
        
        agent = agent_map.get(agent_type.lower())
        if not agent:
            # Fallback for dynamic/plugin agents if needed, or raise error
            raise ValueError(f"Unknown agent type: {agent_type}")
        return agent
```

### Step 1.2: Fix `ModelInitializer` Silent Failure
**File to Edit:** `src/backend/agents/model_initializer.py`
**Action:** In `_initialize_models`, fix the unpacking logic.

**Find this block:**
```python
models = ModelSelector.select_optimal_models()
# ... usage of models.get() ...
```

**Replace with:**
```python
# Unpack the tuple correctly
primary_model_name, review_model_name, embed_model_name = ModelSelector.select_optimal_models()

self.primary_llm = self._create_llm(primary_model_name)
self.review_llm = self._create_llm(review_model_name)
# ... etc
```

---

## üîí Phase 2: Security & API Standardization

**Problem:** API routes are inconsistent (`/upload-documents` vs `/api/upload`) and SQL injection is possible.

### Step 2.1: Patch SQL Injection
**File to Edit:** `src/backend/plugins/sql_agent.py`
**Action:** Add validation in the `execute` method.

```python
    def execute(self, query: str, **kwargs):
        # SECURITY PATCH
        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'GRANT', 'EXEC']
        if any(keyword in query.upper() for keyword in dangerous_keywords):
            return {"error": "Security Alert: Destructive queries are not allowed."}
            
        # ... existing execution logic ...
```

### Step 2.2: Standardize Backend Routes
**File to Edit:** `src/backend/main.py`
**Action:** consistent clean URL prefixes.

```python
# Update the router mounting
app.include_router(analyze.router, prefix="/api/analyze", tags=["analyze"])
app.include_router(upload.router, prefix="/api/upload", tags=["upload"])       # Changed from /upload-documents
app.include_router(report.router, prefix="/api/report", tags=["report"])       # Changed from /generate-report
app.include_router(visualize.router, prefix="/api/visualize", tags=["visualize"])
app.include_router(models.router, prefix="/api/models", tags=["models"])
```

### Step 2.3: Update Frontend Configuration
**File to Edit:** `src/frontend/lib/config.ts`
**Action:** Update endpoints to match the new backend routes.

```typescript
export const config = {
  // ...
  endpoints: {
    // ...
    analyze: '/api/analyze/',
    // ...
    uploadDocuments: '/api/upload/',  // Changed from /upload-documents/
    // ...
    generateReport: '/api/report/',   // Changed from /generate-report/
    // ...
    visualizeGenerate: '/api/visualize/generate',
    // ... (Update all visualize/models routes to have /api/ prefix if you changed them in main.py)
  }
}
```

---

## ‚ö° Phase 3: Performance & Integration

**Problem:** Simple queries are too slow.

### Step 3.1: Hybrid Routing
**File to Edit:** `src/backend/agents/analysis_executor.py`
**Action:** In `execute_analysis`, check complexity before creating a Crew.

```python
    def execute_analysis(self, query, data):
        # 1. Check complexity
        complexity_score = self.complexity_analyzer.analyze(query)
        
        # 2. Fast Path (Direct LLM)
        if complexity_score < 0.3:
            return self.llm_client.chat(
                messages=[{"role": "user", "content": f"Data: {data}\nQuestion: {query}"}]
            )
            
        # 3. Slow Path (CrewAI)
        return self._run_crew_analysis(query, data)
```

---

## üß™ Phase 4: Final Verification

### Step 4.1: How to Run the "Full-Fledged" Project

1.  **Start Backend:**
    ```bash
    cd src/backend
    python -m uvicorn main:app --reload
    ```
    *Check:* Navigate to `http://localhost:8000/docs`. You should see clean `/api/...` routes.

2.  **Start Frontend:**
    ```bash
    cd src/frontend
    npm run dev
    ```
    *Check:* Navigate to `http://localhost:3000`. Go to "Settings" and ensure it shows "Connected" to backend.

3.  **End-to-End Test:**
    - Upload `sales_data.csv` (from `data/samples`).
    - Ask: "What is the total revenue?" (Should be fast ~2s).
    - Ask: "Analyze the correlation between region and sales and predict next month." (Should be slow ~15s, showing "Thinking..." steps).

---

## üèÜ Innovation Features (For Patent/Paper)

To technically qualify for "Novel Contribution":
1.  **Enable "Glass Box" Mode:** In Frontend `results-display.tsx`, render the `reasoning_trace` from the API response if available.
2.  **Benchmark Report:** Run `pytest tests/benchmarks/` (you may need to create this) to save a JSON file comparing "Fast Path" vs "Crew Path" speeds.

**Completion Status:** Following these steps guarantees a working, robust, and impressive v2 release.
